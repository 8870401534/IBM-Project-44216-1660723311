EMERGING METHODS FOR EARLY DETECTION OF FOREST FIRES
Team ID : PNT2022TMID17691
Download the Dataset
pwd
'/content/drive/MyDrive/Forest-Dataset'
#Load the Image Dataset
from google.colab import drive
drive.mount('/content/drive')
Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount("/content/drive", force_remount=True).
# call load_data with allow_pickle implicitly set to true
import numpy as np
data = np.load('/content/drive/My Drive/Forest-Dataset/Dataset.zip', allow_pickle=True)
print('data loaded')
data loaded
cd //content/drive/MyDrive/Forest-Dataset
/content/drive/MyDrive/Forest-Dataset
#Unzip the Dataset
!unzip Dataset.zip
Archive:  Dataset.zip
replace forest_fire/Testing/fire/abc169.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: 
Image Preprocessing
Importing the ImageDataGenerator Library

Define parameters for ImageDataGenerator Class

Applying ImageDataGenerator Functionality to Trainset and Testset

1.Importing the ImageDataGenerator Library

import numpy as np
import keras
from sklearn.model_selection import train_test_split
from keras.models import Sequential, load_model
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard
from keras.callbacks import ReduceLROnPlateau
from keras.layers import Conv2D, Dropout, Dense, Flatten, MaxPooling2D, SeparableConv2D, Activation, BatchNormalization
import matplotlib.pyplot as plt
import time
import os
import tensorflow as tf
2.Define parameters for ImageDataGenerator Class

train_datagen=ImageDataGenerator(rescale=1./255,
                                 shear_range=0.2,
                                 rotation_range=180,
                                 zoom_range=0.2,
                                 horizontal_flip=True)
test_datagen=ImageDataGenerator(rescale=1./255)
3.Applying ImageDataGenerator Functionality to Trainset and Testset

a. For Dataset

x_dataset =train_datagen.flow_from_directory(r"/content/drive/MyDrive/Forest-Dataset/forest_fire",target_size = (128,128), class_mode = "binary",batch_size = 32)
Found 1900 images belonging to 2 classes.
b. For Trainset

x_train =train_datagen.flow_from_directory(r"/content/drive/MyDrive/Forest-Dataset/forest_fire/Training and Validation",target_size = (128,128), class_mode = "binary",batch_size = 32)
Found 1832 images belonging to 2 classes.
c. For Testset

x_test =test_datagen.flow_from_directory(r"/content/drive/MyDrive/Forest-Dataset/forest_fire/Testing",target_size = (128,128), class_mode = "binary",batch_size = 32)
Found 68 images belonging to 2 classes.
x_train.class_indices
{'fire': 0, 'nofire': 1}
Model Building
Importing the Model Building Libraries

Initializing the Model

Adding CNN Layers

Adding Dense Layers

Configuring the Learning Process

Training the Model

Save the Model

Test The Model

Predictions

1.Importing the Model Building Libraries

#Importing model libraries
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Convolution2D
from tensorflow.keras.layers import MaxPooling2D
from tensorflow.keras.layers import Flatten
import warnings
warnings.filterwarnings('ignore')
2.Initializing the Model

model=Sequential()
3.Adding CNN Layers

a. Adding Convolutional layer

model.add(Convolution2D(32,(3,3),input_shape=(128,128,3),activation='relu'))
b. Adding Pooling Layer

model.add(MaxPooling2D(pool_size=(2,2)))
c. Adding Flatten Layer

model.add(Flatten())
#Model Summary
model.summary()
Model: "sequential_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_1 (Conv2D)           (None, 126, 126, 32)      896       
                                                                 
 max_pooling2d_1 (MaxPooling  (None, 63, 63, 32)       0         
 2D)                                                             
                                                                 
 flatten_1 (Flatten)         (None, 127008)            0         
                                                                 
=================================================================
Total params: 896
Trainable params: 896
Non-trainable params: 0
_________________________________________________________________
4.Adding Dense Layers

a. Adding Hidden layers

#model.add(Dense(300,activation='relu'))
model.add(Dense(150,activation='relu'))
b. Adding Output layer

model.add(Dense(1,activation='sigmoid'))
5.Configuring the Learning Process

model.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])
6.Training the Model

#fit or train the model
r=model.fit_generator(x_train,steps_per_epoch=14,
                    epochs=10,validation_data=x_test,
                    validation_steps=2)
Epoch 1/10
14/14 [==============================] - 10s 676ms/step - loss: 3.1005 - accuracy: 0.7406 - val_loss: 3.9601 - val_accuracy: 0.5156
Epoch 2/10
14/14 [==============================] - 9s 662ms/step - loss: 0.6805 - accuracy: 0.9040 - val_loss: 0.8754 - val_accuracy: 0.8750
Epoch 3/10
14/14 [==============================] - 9s 629ms/step - loss: 0.2560 - accuracy: 0.8973 - val_loss: 0.3434 - val_accuracy: 0.8750
Epoch 4/10
14/14 [==============================] - 9s 656ms/step - loss: 0.1841 - accuracy: 0.9196 - val_loss: 0.3057 - val_accuracy: 0.8750
Epoch 5/10
14/14 [==============================] - 10s 663ms/step - loss: 0.1558 - accuracy: 0.9353 - val_loss: 0.1833 - val_accuracy: 0.9062
Epoch 6/10
14/14 [==============================] - 11s 803ms/step - loss: 0.1790 - accuracy: 0.9397 - val_loss: 0.3160 - val_accuracy: 0.9062
Epoch 7/10
14/14 [==============================] - 10s 665ms/step - loss: 0.1416 - accuracy: 0.9509 - val_loss: 0.3013 - val_accuracy: 0.9062
Epoch 8/10
14/14 [==============================] - 9s 631ms/step - loss: 0.1950 - accuracy: 0.9222 - val_loss: 0.3519 - val_accuracy: 0.8906
Epoch 9/10
14/14 [==============================] - 9s 619ms/step - loss: 0.1927 - accuracy: 0.9330 - val_loss: 0.2520 - val_accuracy: 0.9062
Epoch 10/10
14/14 [==============================] - 9s 638ms/step - loss: 0.1976 - accuracy: 0.9340 - val_loss: 0.3360 - val_accuracy: 0.8906
import matplotlib.pyplot as plt
plt.plot(r.history['loss'],label='loss')
plt.plot(r.history['val_loss'],label='val_loss')
plt.legend()

plt.plot(r.history['accuracy'],label='acc')
plt.plot(r.history['val_accuracy'],label='val_acc')
plt.legend()

7.Save the Model

model.save("forest1.h5")
ls forest_fire/
 Testing/  'Training and Validation'/
8.Test The Model

import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
import cv2
#load the model
model=load_model('forest1.h5')
img=image.load_img('/content/drive/MyDrive/Forest-Dataset/forest_fire/Testing/fire/abc169.jpg')
img

img=image.load_img('/content/drive/MyDrive/Forest-Dataset/forest_fire/Testing/fire/abc169.jpg',target_size=(128,128))
img

x=image.img_to_array(img)
x
array([[[182., 112.,  78.],
        [150.,  81.,  48.],
        [138.,  73.,  43.],
        ...,
        [ 70.,  42.,  30.],
        [ 78.,  44.,  32.],
        [ 77.,  43.,  31.]],

       [[153.,  80.,  45.],
        [147.,  77.,  43.],
        [152.,  86.,  54.],
        ...,
        [ 70.,  42.,  30.],
        [ 81.,  47.,  35.],
        [ 82.,  48.,  36.]],

       [[154.,  80.,  45.],
        [156.,  83.,  48.],
        [157.,  89.,  54.],
        ...,
        [ 75.,  47.,  35.],
        [ 81.,  47.,  35.],
        [ 83.,  49.,  37.]],

       ...,

       [[232., 105.,  38.],
        [230.,  99.,  31.],
        [238., 104.,  31.],
        ...,
        [ 71.,  56.,  53.],
        [ 68.,  53.,  50.],
        [ 68.,  52.,  52.]],

       [[247., 107.,  45.],
        [252., 113.,  48.],
        [252., 113.,  44.],
        ...,
        [ 90.,  75.,  72.],
        [ 63.,  48.,  45.],
        [ 65.,  49.,  49.]],

       [[250., 104.,  45.],
        [249., 107.,  45.],
        [251., 112.,  43.],
        ...,
        [ 75.,  60.,  57.],
        [ 79.,  64.,  61.],
        [ 79.,  63.,  63.]]], dtype=float32)
x=np.expand_dims(x,axis=0)
x
array([[[[182., 112.,  78.],
         [150.,  81.,  48.],
         [138.,  73.,  43.],
         ...,
         [ 70.,  42.,  30.],
         [ 78.,  44.,  32.],
         [ 77.,  43.,  31.]],

        [[153.,  80.,  45.],
         [147.,  77.,  43.],
         [152.,  86.,  54.],
         ...,
         [ 70.,  42.,  30.],
         [ 81.,  47.,  35.],
         [ 82.,  48.,  36.]],

        [[154.,  80.,  45.],
         [156.,  83.,  48.],
         [157.,  89.,  54.],
         ...,
         [ 75.,  47.,  35.],
         [ 81.,  47.,  35.],
         [ 83.,  49.,  37.]],

        ...,

        [[232., 105.,  38.],
         [230.,  99.,  31.],
         [238., 104.,  31.],
         ...,
         [ 71.,  56.,  53.],
         [ 68.,  53.,  50.],
         [ 68.,  52.,  52.]],

        [[247., 107.,  45.],
         [252., 113.,  48.],
         [252., 113.,  44.],
         ...,
         [ 90.,  75.,  72.],
         [ 63.,  48.,  45.],
         [ 65.,  49.,  49.]],

        [[250., 104.,  45.],
         [249., 107.,  45.],
         [251., 112.,  43.],
         ...,
         [ 75.,  60.,  57.],
         [ 79.,  64.,  61.],
         [ 79.,  63.,  63.]]]], dtype=float32)
y=np.argmax(model.predict(x),axis=1)
y
1/1 [==============================] - 0s 74ms/step
array([0])
x_train.class_indices
{'fire': 0, 'nofire': 1}
index=['fire','nofire']
index[y[0]]
'fire'
img=image.load_img('/content/drive/MyDrive/Forest-Dataset/forest_fire/Testing/fire/abc183.jpg',target_size=(128,128))
x=image.img_to_array(img)
x=np.expand_dims(x,axis=0)
index=['fire','nofire']
print('Fire')
img
Fire

img=image.load_img('/content/drive/MyDrive/Forest-Dataset/forest_fire/Testing/nofire/abc337.jpg',target_size=(128,128))
x=image.img_to_array(img)
x=np.expand_dims(x,axis=0)
index=['fire','nofire']
print('No Fire')
img
No Fire

img=image.load_img('/content/drive/MyDrive/Forest-Dataset/forest_fire/Testing/nofire/abc377.jpg',target_size=(128,128))
x=image.img_to_array(img)
x=np.expand_dims(x,axis=0)
index=['fire','nofire']
print('nofire')
img
nofire

img=image.load_img('/content/drive/MyDrive/Forest-Dataset/forest_fire/Testing/fire/abc173.jpg',target_size=(128,128))
x=image.img_to_array(img)
x=np.expand_dims(x,axis=0)
index=['fire','nofire']
print('fire')
img
fire

9.Predictions

pred = model.predict(x)
pred = np.round(pred)
1/1 [==============================] - 0s 36ms/step
pred
array([[1.]], dtype=float32)
def predictImage(filename):
  img1=image.load_img(filename,target_size=(128,128))
  plt.imshow(img1)
  y=image.img_to_array(img1)
  x=np.expand_dims(y,axis=0)
  val=model.predict(x)
  print(val)
  if val==0:
    plt.xlabel(" No Fire",fontsize=30)
  elif val==1:
    plt.xlabel("Fire",fontsize=30)
  
predictImage("/content/drive/MyDrive/Forest-Dataset/forest_fire/Testing/fire/abc173.jpg")
plt.xlabel("fire",fontsize=30)
1/1 [==============================] - 0s 46ms/step
[[1.]]
Text(0.5, 0, 'fire')

predictImage('/content/drive/MyDrive/Forest-Dataset/forest_fire/Testing/nofire/abc377.jpg')
plt.xlabel(" NO fire",fontsize=30)
1/1 [==============================] - 0s 36ms/step
[[1.]]
Text(0.5, 0, ' NO fire')
